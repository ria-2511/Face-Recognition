{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Applications Lab Evaluation-2 - Face Recognition Project using Deep Learning \n",
    "\n",
    "### Submitted by-\n",
    "#### Ria Soam 101803258\n",
    "#### Aashima Tandon 101803213\n",
    "#### Karanbir Singh 101803235\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Face recognition is a method of identifying or verifying the identity of an individual using their face. Face recognition systems can be used to identify people in photos, video, or in real-time. It involves comparing one input image to all images in an image library in order to determine who the input image belongs to. Or if it does not belong to the database at all.\n",
    "\n",
    "#### How Facial Recognition Works\n",
    "\n",
    "#### Step 1: Face detection\n",
    "The camera detects and locates the image of a face, either alone or in a crowd. The image may show the person looking straight ahead or in profile.\n",
    "\n",
    "#### Step 2: Face analysis\n",
    "Next, an image of the face is captured and analyzed by a neural network algorithm. The program examines the physical features of an individual’s face to distinguish uniqueness from others. Key factors include the distance between your eyes, the depth of your eye sockets, the distance from forehead to chin, the shape of your cheekbones, and the contour of the lips, ears, and chin. The aim is to identify the facial landmarks that are key to distinguishing your face.\n",
    "\n",
    "#### Step 3: Converting the image to data\n",
    "The face capture process transforms analog information (a face) into a set of digital information (data) based on the person's facial features. Your face's analysis is essentially turned into a mathematical formula. The numerical code is called a faceprint.\n",
    "\n",
    "#### Step 4: Finding a match\n",
    "Your faceprint is then compared against a database of other known faces. For example, the FBI has access to up to 650 million photos, drawn from various state databases\n",
    "\n",
    "\n",
    "##### One key factor that can strongly affect the effectiveness of facial recognition is lighting. In order for facial recognition to work, it’s very important to have good lighting to clearly show all of the individual’s facial features. \n",
    "##### The system would have a lot of difficulties identifying the individual. It’s also possible that the picture in the system that is used to match with the individual is outdated, meaning that the system would likely be less accurate in identifying. Regardless of these obstacles, facial recognition is still one of the most accurate methods of identifying an individual and holds a lot of potential for the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(img, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        x=x-10\n",
    "        y=y-10\n",
    "        cropped_face = img[y:y+h+50, x:x+w+50]\n",
    "\n",
    "    return cropped_face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 200 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (400, 400))\n",
    "        #face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = 'C:/Users/riaso/Downloads/Images/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 200: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'C:/Users/riaso/Downloads/Datasets/Train'\n",
    "valid_path = 'C:/Users\\riaso/Downloads/Datasets/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessing layer to the front of VGG\n",
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't train existing weights\n",
    "for layer in vgg.layers:\n",
    "  layer.trainable = False\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # useful for getting number of classes\n",
    "folders = glob('C:/Users/riaso/Downloads/Datasets/Train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(vgg.output)\n",
    "# x = Dense(1000, activation='relu')(x)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model object\n",
    "model = Model(inputs=vgg.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 125445    \n",
      "=================================================================\n",
      "Total params: 14,840,133\n",
      "Trainable params: 125,445\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 678 images belonging to 5 classes.\n",
      "Found 136 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('C:/Users/riaso/Downloads/Datasets/Train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:/Users/riaso/Downloads/Datasets/Test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRIPLET DATA GENERATOR \n",
    "#class DataGenerator(tf.keras.utils.Sequence):\n",
    "#     def __init__(self, dataset_path, batch_size=32, shuffle=True):\n",
    "#         self.dataset = self.curate_dataset(dataset_path)\n",
    "#         self.dataset_path = dataset_path\n",
    "#         self.shuffle = shuffle\n",
    "#         self.batch_size =batch_size\n",
    "#         self.no_of_people = len(list(self.dataset.keys()))\n",
    "#         self.on_epoch_end()\n",
    "        \n",
    "#     def __getitem__(self, index):\n",
    "#         people = list(self.dataset.keys())[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "#         P = []\n",
    "#         A = []\n",
    "#         N = []\n",
    "        \n",
    "#         for person in people:\n",
    "#             anchor_index = random.randint(0, len(self.dataset[person])-1)\n",
    "#             a = self.get_image(person, anchor_index)\n",
    "            \n",
    "#             positive_index = random.randint(0, len(self.dataset[person])-1)\n",
    "#             while positive_index == anchor_index:\n",
    "#                 positive_index = random.randint(0, len(self.dataset[person])-1)\n",
    "#             p = self.get_image(person, positive_index)\n",
    "            \n",
    "#             negative_person_index = random.randint(0, self.no_of_people - 1)\n",
    "#             negative_person = list(self.dataset.keys())[negative_person_index]\n",
    "#             while negative_person == person:\n",
    "#                 negative_person_index = random.randint(0, self.no_of_people - 1)\n",
    "#                 negative_person = list(self.dataset.keys())[negative_person_index]\n",
    "            \n",
    "#             negative_index = random.randint(0, len(self.dataset[negative_person])-1)\n",
    "#             n = self.get_image(negative_person, negative_index)\n",
    "#             P.append(p)\n",
    "#             A.append(a)\n",
    "#             N.append(n)\n",
    "#         A = np.asarray(A)\n",
    "#         N = np.asarray(N)\n",
    "#         P = np.asarray(P)\n",
    "#         return [A, P, N]\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.no_of_people // self.batch_size\n",
    "        \n",
    "#     def curate_dataset(self, dataset_path):\n",
    "#         with open(os.path.join(dataset_path, 'list.txt'), 'r') as f:\n",
    "#             dataset = {}\n",
    "#             image_list = f.read().split()\n",
    "#             for image in image_list:\n",
    "#                 folder_name, file_name = image.split('/')\n",
    "#                 if folder_name in dataset.keys():\n",
    "#                     dataset[folder_name].append(file_name)\n",
    "#                 else:\n",
    "#                     dataset[folder_name] = [file_name]\n",
    "#         return dataset\n",
    "    \n",
    "#     def on_epoch_end(self):\n",
    "#         if self.shuffle:\n",
    "#             keys = list(self.dataset.keys())\n",
    "#             random.shuffle(keys)\n",
    "#             dataset_ =  {}\n",
    "#             for key in keys:\n",
    "#                 dataset_[key] = self.dataset[key]\n",
    "#             self.dataset = dataset_\n",
    "            \n",
    "#     def get_image(self, person, index):\n",
    "#         # print(os.path.join(self.dataset_path, os.path.join('images/' + person, self.dataset[person][index])))\n",
    "#         img = cv2.imread(os.path.join(self.dataset_path, os.path.join('images/' + person, self.dataset[person][index])))\n",
    "#         img = cv2.resize(img, (224, 224))\n",
    "#         img = np.asarray(img, dtype=np.float64)\n",
    "#         img = preprocess_input(img)\n",
    "#         return img\n",
    "    \n",
    "# data_generator = DataGenerator(dataset_path='./dataset/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r=model.fit_generator(training_set,\\n                         samples_per_epoch = 8000,\\n                         nb_epoch = 5,\\n                         validation_data = test_set,\\n                         nb_val_samples = 2000)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''r=model.fit_generator(training_set,\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 5,\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 2000)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riaso\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22/22 [==============================] - 243s 10s/step - loss: 0.7781 - accuracy: 0.7224 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 194s 9s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 9.3789e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 201s 9s/step - loss: 4.9254e-04 - accuracy: 1.0000 - val_loss: 5.5814e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 210s 10s/step - loss: 0.0014 - accuracy: 0.9990 - val_loss: 3.7643e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 219s 10s/step - loss: 6.3651e-04 - accuracy: 1.0000 - val_loss: 2.8001e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=5,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('facefeatures_new_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5gU9Z3v8fe3e27cr8PFmSagEpXrAD2EXXcxRqOgK2hEBhOjyeOJT07W3ZP1OR7d5Gxi9I+4mt14zJqL2TWPuRhA1IREElYTCSbRyICAIKKAIsN1uA33y0x/zx9dMzRDD/Qwl+ru+byep5nuqt+v6jvF9Keqq6qrzN0REZH8FQm7ABER6VgKehGRPKegFxHJcwp6EZE8p6AXEclzBWEX0NzAgQN9+PDhYZchIpJTli9fvtvdS9ONy7qgHz58ONXV1WGXISKSU8xsc0vjtOtGRCTPKehFRPKcgl5EJM9l3T56EclfJ0+epKamhmPHjoVdSs4qKSmhvLycwsLCjPso6EWk09TU1NCrVy+GDx+OmYVdTs5xd/bs2UNNTQ0jRozIuJ923YhIpzl27BgDBgxQyJ8nM2PAgAGt/kSkoBeRTqWQb5vzWX55E/R1R07y2Mvvsn7HwbBLERHJKhkFvZlNM7P1ZrbBzO5PM/6LZvaWma00sz+a2aiUcf8c9FtvZte2Z/GpHOe7SzbyzF9a/M6AiHRx+/fv57vf/e559b3uuuvYv39/xu0feOABvvWtb53XvNrbOYPezKLAE8B0YBRwa2qQB55x97HuXgE8Avx70HcUMAcYDUwDvhtMr9317V7EtaOH8IuV2zh2sqEjZiEiOe5sQd/QcPbcWLRoEX379u2IsjpcJlv0k4EN7r7J3U8Ac4GZqQ3c/UDKyx5A422rZgJz3f24u78PbAim1yGq4jHqjp5k8dodHTULEclh999/Pxs3bqSiooJ7772XJUuWcOWVV/LpT3+asWPHAnDjjTcyadIkRo8ezZNPPtnUd/jw4ezevZsPPviAyy67jC984QuMHj2aa665hqNHj551vitXrmTKlCmMGzeOm266iX379gHw+OOPM2rUKMaNG8ecOXMA+MMf/kBFRQUVFRVMmDCBgwfbvjs6k9Mry4AtKa9rgI81b2Rmfw/cAxQBn0jp+3qzvmVp+t4F3AUwbNiwTOpO668vGkB5v27Mr97CzIozZiMiWeQbv1rL29sOnLthK4y6oDdfv2F0i+Mffvhh1qxZw8qVKwFYsmQJb7zxBmvWrGk6XfGpp56if//+HD16lMrKSm6++WYGDBhw2nTee+89fv7zn/PDH/6Q2bNn89xzz3Hbbbe1ON/bb7+d73znO1xxxRV87Wtf4xvf+AaPPfYYDz/8MO+//z7FxcVNu4W+9a1v8cQTT3D55Zdz6NAhSkpK2rpYMtqiT3eI94wbzbr7E+5+EXAf8H9b2fdJd4+7e7y0NO3F1zISiRi3TIrxpw172LL3yHlPR0S6jsmTJ592Tvrjjz/O+PHjmTJlClu2bOG99947o8+IESOoqKgAYNKkSXzwwQctTr+uro79+/dzxRVXAHDHHXewdOlSAMaNG8dnPvMZfvrTn1JQkNzuvvzyy7nnnnt4/PHH2b9/f9PwtshkCjVALOV1ObDtLO3nAt87z75tdku8nMd+9y7PVm/hnmsu6chZiUgbnG3LuzP16NGj6fmSJUt4+eWXee211+jevTsf//jH056zXlxc3PQ8Go2ec9dNS1588UWWLl3KwoULeeihh1i7di33338/119/PYsWLWLKlCm8/PLLXHrppec1/UaZbNEvA0aa2QgzKyJ5cHVhagMzG5ny8nqgcRW4EJhjZsVmNgIYCbzRporP4YK+3Zg6spRnl9fQkDjjw4OIdGG9evU66z7vuro6+vXrR/fu3XnnnXd4/fXXW2ybqT59+tCvXz9effVVAH7yk59wxRVXkEgk2LJlC1deeSWPPPII+/fv59ChQ2zcuJGxY8dy3333EY/Heeedd9pcwzm36N293szuBhYDUeApd19rZg8C1e6+ELjbzK4GTgL7gDuCvmvNbD7wNlAP/L27d/gpMVWVMb70sxUsfa+WKy8Z1NGzE5EcMWDAAC6//HLGjBnD9OnTuf76608bP23aNL7//e8zbtw4LrnkEqZMmdIu83366af54he/yJEjR7jwwgv50Y9+RENDA7fddht1dXW4O//0T/9E3759+Zd/+RdeeeUVotEoo0aNYvr06W2ev7ln11ZvPB73tt545ER9ginf/B0fG9Gf7902qZ0qE5G2WrduHZdddlnYZeS8dMvRzJa7ezxd+7z5ZmyqooIIN00o4+V1O9lz6HjY5YiIhCovgx6Su29ONjgvvLk17FJEREKVt0H/0cG9qIj1Zd6yLWTb7ikRkc6Ut0EPMKcyxnu7DvHmlsyvTyEikm/yOuj/bvwFdC+KMn/ZlnM3FhHJU3kd9D2LC7h+7FB+tWobh4/Xh12OiEgo8jroIXlQ9vCJBl5cvT3sUkQkB/Xs2bNVw7NR3gf9pI/048LSHsyr1u4bEema8j7ozYyqeIzlm/exYZfuPiXSld13332nXY/+gQce4N/+7d84dOgQV111FRMnTmTs2LH88pe/zHia7s69997LmDFjGDt2LPPmzQNg+/btTJ06lYqKCsaMGcOrr75KQ0MDn/vc55rafvvb32733zGdtl8WLQd8amI5jy5ez/zqGr5ynb6VJ5IVfnM/7Hirfac5ZCxMf7jF0XPmzOHLX/4yX/rSlwCYP38+v/3tbykpKeGFF16gd+/e7N69mylTpjBjxoyM7s/6/PPPs3LlSlatWsXu3buprKxk6tSpPPPMM1x77bV89atfpaGhgSNHjrBy5Uq2bt3KmjVrAFp1x6q2yPsteoDSXsVcddkgnl9Rw4n6RNjliEhIJkyYwK5du9i2bRurVq2iX79+DBs2DHfnK1/5CuPGjePqq69m69at7Ny5M6Np/vGPf+TWW28lGo0yePBgrrjiCpYtW0ZlZSU/+tGPeOCBB3jrrbfo1asXF154IZs2beIf/uEf+O1vf0vv3r07+DdO6hJb9JA8KLt47U5+/85Opo0ZGnY5InKWLe+ONGvWLBYsWMCOHTua7ur0s5/9jNraWpYvX05hYSHDhw9Pe3nidFr6QubUqVNZunQpL774Ip/97Ge59957uf3221m1ahWLFy/miSeeYP78+Tz11FPt9ru1pEts0QNMHVnK4N7FzNM59SJd2pw5c5g7dy4LFixg1qxZQPLyxIMGDaKwsJBXXnmFzZs3Zzy9qVOnMm/ePBoaGqitrWXp0qVMnjyZzZs3M2jQIL7whS9w5513smLFCnbv3k0ikeDmm2/moYceYsWKFR31a56my2zRF0QjzJpUzveWbGRH3TGG9Gn77blEJPeMHj2agwcPUlZWxtChyU/3n/nMZ7jhhhuIx+NUVFS06kYfN910E6+99hrjx4/HzHjkkUcYMmQITz/9NI8++iiFhYX07NmTH//4x2zdupXPf/7zJBLJXcjf/OY3O+R3bC4vL1Pcks17DnPFo0v439d8lLs/MfLcHUSkXekyxe1Dlyk+i48M6MGUC/szv7qGhO4+JSJdRJcKekgelP1w7xFef39P2KWIiHSKLhf008cMpVdJgS50JhKSbNtdnGvOZ/l1uaAvKYxyY0UZi9bsoO7IybDLEelSSkpK2LNnj8L+PLk7e/bsoaSkdSeTdJmzblJVVcb4yeub+eWqrdz+V8PDLkekyygvL6empoba2tqwS8lZJSUllJeXt6pPlwz6MWV9GDW0N/OWbVHQi3SiwsJCRowYEXYZXU6X23XTqKoyxtptB1iztS7sUkREOlSXDfobK8ooKogwX5cvFpE8l1HQm9k0M1tvZhvM7P404+8xs7fNbLWZ/c7MPpIyrsHMVgaPhe1ZfFv06V7ItNFD+MWbWzl2siHsckREOsw5g97MosATwHRgFHCrmY1q1uxNIO7u44AFwCMp4466e0XwmNFOdbeLOZUxDhyrZ/HaHWGXIiLSYTLZop8MbHD3Te5+ApgLzExt4O6vuPuR4OXrQOsOCYdkyoUDiPXvxtw3tPtGRPJXJkFfBqQmYU0wrCV3Ar9JeV1iZtVm9rqZ3XgeNXaYSMSYPSnGa5v2sHnP4bDLERHpEJkEfbpbrKT9toOZ3QbEgUdTBg8LLrTzaeAxM7soTb+7gpVBdWefXzsrXk7E4Nnqmk6dr4hIZ8kk6GuAWMrrcmBb80ZmdjXwVWCGux9vHO7u24Kfm4AlwITmfd39SXePu3u8tLS0Vb9AWw3t042pHy1lwfIaGnShMxHJQ5kE/TJgpJmNMLMiYA5w2tkzZjYB+AHJkN+VMryfmRUHzwcClwNvt1fx7aUqHmPHgWMsfVff1hOR/HPOoHf3euBuYDGwDpjv7mvN7EEzazyL5lGgJ/Bss9MoLwOqzWwV8ArwsLtnXdBfddlgBvQo0t2nRCQvZXQJBHdfBCxqNuxrKc+vbqHfn4GxbSmwMxQVRPjUxDJ+9KcP2H3oOAN7FoddkohIu+my34xtrqoyRn3CeX6FDsqKSH5R0AcuHtSLicP6Mm/ZFl1CVUTyioI+RVVljI21h1nx4b6wSxERaTcK+hTXj7uA7kVRHZQVkbyioE/Rs7iAvxs3lF+v3s6h4/VhlyMi0i4U9M1UVcY4cqKBF1ef8Z0wEZGcpKBvZuKwflw8qCdztftGRPKEgr4ZM6MqHuPND/fz3s6DYZcjItJmCvo0bppYRkHEdFBWRPKCgj6NgT2LufqywTz/5lZO1CfCLkdEpE0U9C2oqoyx9/AJfrduZ9iliIi0iYK+BVM/WsqQ3iXM083DRSTHKehbEI0YsyaVs/TdWrbtPxp2OSIi501Bfxaz4zESDguW60JnIpK7FPRnMWxAd/76ogHMr95CQnefEpEcpaA/h6rKGDX7jvLapj1hlyIicl4U9Odw7egh9C4p0Dn1IpKzFPTnUFIY5cYJZfx27Q7qjpwMuxwRkVZT0GdgdjzGifoEv1i5NexSRERaTUGfgTFlfRh9QW/m6u5TIpKDFPQZmlMZY932A6zZeiDsUkREWkVBn6EZFWUUF0SYV/1h2KWIiLSKgj5DfboVMn3MEH65chvHTjaEXY6ISMYU9K0wuzLGwWP1/GbN9rBLERHJWEZBb2bTzGy9mW0ws/vTjL/HzN42s9Vm9jsz+0jKuDvM7L3gcUd7Ft/ZpowYwLD+3XVOvYjklHMGvZlFgSeA6cAo4FYzG9Ws2ZtA3N3HAQuAR4K+/YGvAx8DJgNfN7N+7Vd+54pEjNnxcl7ftJfNew6HXY6ISEYy2aKfDGxw903ufgKYC8xMbeDur7j7keDl60B58Pxa4CV33+vu+4CXgGntU3o4Zk2KETGYr8sXi0iOyCToy4DUVKsJhrXkTuA3relrZneZWbWZVdfW1mZQUniG9Cnh45cM4tnqGuobdPcpEcl+mQS9pRmW9ltDZnYbEAcebU1fd3/S3ePuHi8tLc2gpHDNjsfYdfA4f3g3u1dKIiKQWdDXALGU1+XAtuaNzOxq4KvADHc/3pq+ueaqywYxsGeRDsqKSE7IJOiXASPNbISZFQFzgIWpDcxsAvADkiG/K2XUYuAaM+sXHIS9JhiW0wqjET41sZzfv7OL2oPHz91BRCRE5wx6d68H7iYZ0OuA+e6+1sweNLMZQbNHgZ7As2a20swWBn33Ag+RXFksAx4MhuW82fEY9Qnn+RW6+5SIZDfLtot0xeNxr66uDruMjNz8vT+z78gJfnfPFZilOxwhItI5zGy5u8fTjdM3Y9ugKh5jU+1hqjfvC7sUEZEWKejb4PpxQ+lRFNVBWRHJagr6NuhRXMAN4y/gxdXbOXhMd58SkeykoG+j2ZUxjp5s4NerdaEzEclOCvo2mhDry8hBPbX7RkSyloK+jcyMqsoYK7fs592dB8MuR0TkDAr6dnDThDIKo6atehHJSgr6djCgZzGfHDWY51fUcLxed58SkeyioG8ns+Mx9h05yctv7zp3YxGRTqSgbyd/O7KUC/qUME/XqReRLKOgbyfRiDFrUjmvvlfL1v1Hwy5HRKSJgr4d3RKP4Q4LqnWhMxHJHgr6dhTr353LLx7As8u3kEhk18XiRKTrUtC3s9nxGDX7jvLnjXvCLkVEBFDQt7trRw+hT7dC5i77MOxSREQABX27KymMctOEMv577U72HT4RdjkiIgr6jjA7HuNEQ4JfrNwadikiIgr6jjDqgt6MLevDvGVbyLY7eIlI16Og7yCzK2O8s+Mgb22tC7sUEeniFPQdZMb4CyguiOhCZyISOgV9B+nTrZDrxg5l4cptHD2hC52JSHgU9B2oqjLGweP1LHpLd58SkfAo6DvQx0b0Z/iA7rrQmYiEKqOgN7NpZrbezDaY2f1pxk81sxVmVm9ms5qNazCzlcFjYXsVngvMjFviMd54fy/v7z4cdjki0kWdM+jNLAo8AUwHRgG3mtmoZs0+BD4HPJNmEkfdvSJ4zGhjvTln1qRyIgbztVUvIiHJZIt+MrDB3Te5+wlgLjAztYG7f+Duq4FEB9SY0wb3LuHKSwbx3PIa6hu0eESk82US9GVA6uZoTTAsUyVmVm1mr5vZja2qLk/Mroyx6+BxlqyvDbsUEemCMgl6SzOsNV/3HObuceDTwGNmdtEZMzC7K1gZVNfW5l8YfuLSQQzsWcxcnVMvIiHIJOhrgFjK63JgW6YzcPdtwc9NwBJgQpo2T7p73N3jpaWlmU46ZxRGI9w8qYxX1u9i14FjYZcjIl1MJkG/DBhpZiPMrAiYA2R09oyZ9TOz4uD5QOBy4O3zLTaXzY7HaEg4z63Qhc5EpHOdM+jdvR64G1gMrAPmu/taM3vQzGYAmFmlmdUAtwA/MLO1QffLgGozWwW8Ajzs7l0y6C8q7Unl8H48W60LnYlI5yrIpJG7LwIWNRv2tZTny0ju0mne78/A2DbWmDdmx2Pcu2A1yz7Yx+QR/cMuR0S6CH0zthNdP24oPYsLdKEzEelUCvpO1L2ogBvGD2XRW9s5cOxk2OWISBehoO9ks+Mxjp5s4FerMj5xSUSkTRT0nawi1pdLBvdivnbfiEgnUdB3MjNjdmWMVTV1vLPjQNjliEgXoKAPwU0TyiiMmg7KikinUNCHoH+PIq4ZNYQX3tzK8XrdfUpEOpaCPiSzK2PsP3KSl97eGXYpIpLnFPQh+ZuLB3JBnxLtvhGRDqegD0k0YsyKx/jjht3U7DsSdjkikscU9CG6ZVLyqhHPVteEXImI5DMFfYhi/bvzNxcPZMHyGhoSutCZiHQMBX3IZsdjbN1/lD9t2B12KSKSpxT0Ibtm9GD6di9knm4eLiIdREEfsuKCKDdWlPHS2p3sO3wi7HJEJA8p6LNAVWWMEw0JXnhTd58SkfanoM8Clw3tzbjyPsxbprtPiUj7U9BniarKGOt3HmRVTV3YpYhInlHQZ4kbxl9ASWFE35QVkXanoM8SvUsKuW7sUH61ahtHTtSHXY6I5BEFfRapisc4dLyeRW/tCLsUEckjCvosMnlEf0YM7KG7T4lIu1LQZxEz45Z4OW98sJeNtYfCLkdE8oSCPsvMmlhONGLM1zdlRaSdZBT0ZjbNzNab2QYzuz/N+KlmtsLM6s1sVrNxd5jZe8HjjvYqPF8N6l3ClZcM4rnlWznZkAi7HBHJA+cMejOLAk8A04FRwK1mNqpZsw+BzwHPNOvbH/g68DFgMvB1M+vX9rLzW1VljN2HjvPKO7vCLkVE8kAmW/STgQ3uvsndTwBzgZmpDdz9A3dfDTTfBL0WeMnd97r7PuAlYFo71J3XrryklNJexdp9IyLtIpOgLwNSE6cmGJaJjPqa2V1mVm1m1bW1tRlOOn8VRCPcPLGcV9bXsuvAsbDLEZEcl0nQW5phmV6QJaO+7v6ku8fdPV5aWprhpPPb7Hg5DQlnwQrdfUpE2iaToK8BYimvy4FtGU6/LX27tAtLezJ5eH/m60JnItJGmQT9MmCkmY0wsyJgDrAww+kvBq4xs37BQdhrgmGSgdmVMT7Yc4S/vL837FJEJIedM+jdvR64m2RArwPmu/taM3vQzGYAmFmlmdUAtwA/MLO1Qd+9wEMkVxbLgAeDYZKB68YOoVdxgb4pKyJtYtm2WyAej3t1dXXYZWSNr7zwFs+vqOGNr15N75LCsMsRkSxlZsvdPZ5unL4Zm+Wq4jGOnUywcKUObYjI+VHQZ7lx5X24dEgvnVMvIudNQZ/lzIzZ8Rira+p4e9uBsMsRkRykoM8BN00ooyga0Va9iJwXBX0O6NejiE+OHswLb27l2MmGsMsRkRyjoM8Rcypj1B09yX+/vTPsUkQkxyjoc8TlFw2krG83nVMvIq2moM8RkUjy7lN/3LCbLXuPhF2OiOQQBX0OuSUewwyeXa4LnYlI5hT0OaSsbzf+5uKBLKjeQkMiu77RLCLZS0GfY6oqY2yrO8ar7+m6/SKSGQV9jvnkqMH0616oc+pFJGMK+hxTXBDlpgnlvPT2TvYcOh52OSKSAxT0OaiqMsbJBueFN7eGXYqI5AAFfQ66ZEgvxsf6Mr9ad58SkXNT0OeoqniMd3ceYuWW/WGXIiJZTkGfo24YP5RuhVHm6ZuyInIOCvoc1aukkOvGDuVXq7Zx+Hh92OWISBZT0OewqsoYh0808OJb28MuRUSymII+h1UO78eFA3voQmciclYK+hxmZsyujFG9eR8bdh0KuxwRyVIK+hz3qYllRCPGs/qmrIi0QEGf4wb1KuETlw7iuRU1nGxIhF2OiGShjILezKaZ2Xoz22Bm96cZX2xm84LxfzGz4cHw4WZ21MxWBo/vt2/5Aslz6ncfOsHv1u0KuxQRyULnDHoziwJPANOBUcCtZjaqWbM7gX3ufjHwbeBfU8ZtdPeK4PHFdqpbUnz8klIG9SrWhc5EJK1MtugnAxvcfZO7nwDmAjObtZkJPB08XwBcZWbWfmXK2RREI9w8qZwl63exo+5Y2OWISJbJJOjLgNRNxZpgWNo27l4P1AEDgnEjzOxNM/uDmf1tG+uVFsyOx0g4PLdCd58SkdNlEvTptsybX0mrpTbbgWHuPgG4B3jGzHqfMQOzu8ys2syqa2t1Q43zMWJgDz42oj/zq7eQ0N2nRCRFJkFfA8RSXpcD21pqY2YFQB9gr7sfd/c9AO6+HNgIfLT5DNz9SXePu3u8tLS09b+FAMlvym7ec4S/vL837FJEJItkEvTLgJFmNsLMioA5wMJmbRYCdwTPZwG/d3c3s9LgYC5mdiEwEtjUPqVLc9PHDKVXcYEOyorIac4Z9ME+97uBxcA6YL67rzWzB81sRtDsv4ABZraB5C6axlMwpwKrzWwVyYO0X3R3bW52kG5FUWZUXMCit7ZTd/Rk2OWISJawbLtxRTwe9+rq6rDLyFmra/Yz4z/+xEMzR/PZvxoedjki0knMbLm7x9ON0zdj88zYsj5cOqQX87T7RkQCCvo8Y2bMqYyxZusB1m6rC7scEckCCvo8dOOEMooKIrp8sYgACvq81Ld7EdeOHsIvVm7j2MmGsMsRkZAp6PNUVTxG3dGTLF67I+xSRCRkCvo89dcXDaC8XzfdPFxEFPT5KhIxbpkU488b9/DhniNhlyMiIVLQ57FZ8XLM4Nnl2qoX6coU9HmsrG83po4sZcHyGhp0oTORLktBn+eqKmNsrzvG0vd0VVCRrkpBn+euvmww/XsU6Zx6kS5MQZ/nigoi3DShjJfe3snuQ8fDLkdEQqCg7wKqKmPUJ5wXVmwNuxQRCYGCvgv46OBeVMT6Mq96C9l2tVIR6XgK+i6iqjLGhl2HWPHh/rBLEZFOpqDvIm4YfwHdi6I6KCvSBSnou4iexQVcP3Yov169jcPH68MuR0Q6kYK+C6mqjHH4RAMvrt4ediki0okU9F3IpI/048LSHsxd9mHYpYhIJ1LQdyFmRlU8xooP97Nh18GwyxGRTqKg72I+NbGcgojp8sUiXYiCvosp7VXMJy4dxPMrtnKiPhF2OSLSCRT0XdCcyTH2HD7B79/ZGXYpItIJFPRd0NSRpQzuXazdNyJdREEmjcxsGvD/gCjwn+7+cLPxxcCPgUnAHqDK3T8Ixv0zcCfQAPyjuy9ut+pTHdkLj0+AaFHwKEj+jBRCtDAYFjyPFJ7eJloEkYLT25zWt7BZm0ynf7ZpRTtkMWSiIBph1qRyvrdkI1v2HmFonxKiEcPMQqtJRDrOOYPezKLAE8AngRpgmZktdPe3U5rdCexz94vNbA7wr0CVmY0C5gCjgQuAl83so+7e0N6/CJECGDcbGk5AQ33yZ+IkNJwMhgXPTx6FhrpTbRpOQKL+9DaNw+nA68JY5MwVTsYrjQxWSulWaCnTv2NAA6tsHfd9aw1OMuANsEiEiCVDPxn+kaZhkUgEM4hGIpgZEYtgEWt63di+sW0kEvxsHBeJpLSJEI0QtAvaWoRI1IgSTLOxfSRCQdAvGkwzGokSiSRraWxb0NQ2Ob3oaT8jRKMRomZNwwoiESwatDejIHqqfTSYdzSafF4QjRIxAzMSDg0JP/UTSCSgwZPDEgmngeQ4D9o0uOPuNCQa+yYfp54Hw4O2TdNp3rfpeZq+3tiflOkEwxKcNs/kdGg2naBd8LohdXpN0wlq8+b9nEQwj1P9HMOIGMH/rxE1C/6GrGnjImoEfzPJttGgbdPfjZH8f2uxTbP+Tc/T94+m1NPY34LaIsG0Uqd/2vwiQbvU3ym1fzCNVvU3wyLJGqMRo6Sw/TcCM9minwxscPdNAGY2F5gJpAb9TOCB4PkC4D8suXk4E5jr7seB981sQzC919qn/BQlveG6R9t3momGU8GfSFkxNK4QEifPXEGkW2k0rXBS2jf1PctKKXX6Jw5nPv0MVlCDgJ8WZbAMnORnMWkSDR6tlfBTn5i86aed9jPduCQ7bVxr+voZfU8fZ9Y47vRPdKkbAN70aS9NTWZNQ5PRDm5gWEo9pwpITtfPrNdT2uKn6k75pb35T7em1jQbdvrvciYnXbvmy+D8+jWfRn0L7Zq/3t7tYqb+88IWp3W+Mgn6MiB1Z24N8LGW2rh7vbft/YAAAAXySURBVJnVAQOC4a8361vWfAZmdhdwF8CwYcMyrb3jRaLJR2FJ2JVkzj25gspkRdJwArzxzBsP3lEpPxund8awdO1bMY0z2pO2fSKRSG5dpj73BJ4IXgOJhgTuyeGnxpP86c36BFvDiURjH8cTCRIO7olm404N88ZpBLVGLPj0Y8mDXJHgRQRPfhrCg088yTZ2Wp/G8WdOx9K2OTU9w4M+KcPMiTQGsjlRTvW1Zn2NM6P81PLuiGFpYjLt1VPTtUvTrPnAs0zLSX5i8eBv1YNPMB50cxJNf37JYR60axzmTf/fp16T0sabpsUZbRvHJ180tfMEjX/lHvzTvM3gvsPT/eJtlknQp1tVNV/CLbXJpC/u/iTwJEA8Htd1dNvCLNhVUwCF3cKupk0i6GwBOT9nrtS6tkzeRzVALOV1ObCtpTZmVgD0AfZm2FdERDpQJkG/DBhpZiPMrIjkwdXmO5EWAncEz2cBv/fkZ5mFwBwzKzazEcBI4I32KV1ERDJxzl03wT73u4HFJI9BPeXua83sQaDa3RcC/wX8JDjYupfkyoCg3XySB27rgb/vkDNuRESkRZZtt5aLx+NeXV0ddhkiIjnFzJa7ezzdOB3rEhHJcwp6EZE8p6AXEclzCnoRkTyXdQdjzawW2NyGSQwEdrdTOe1JdbWO6mod1dU6+VjXR9y9NN2IrAv6tjKz6paOPIdJdbWO6mod1dU6Xa0u7boREclzCnoRkTyXj0H/ZNgFtEB1tY7qah3V1Tpdqq6820cvIiKny8ctehERSaGgFxHJczkZ9GY2zczWm9kGM7s/zfhiM5sXjP+LmQ3Pkro+Z2a1ZrYyePyPTqrrKTPbZWZrWhhvZvZ4UPdqM5uYJXV93MzqUpbX1zqprpiZvWJm68xsrZn9rzRtOn2ZZVhXpy8zMysxszfMbFVQ1zfStOn092SGdYXyngzmHTWzN83s12nGte/ycvecepC8VPJG4EKgCFgFjGrW5kvA94Pnc4B5WVLX54D/CGGZTQUmAmtaGH8d8BuSN+WZAvwlS+r6OPDrEJbXUGBi8LwX8G6a/8tOX2YZ1tXpyyxYBj2D54XAX4ApzdqE8Z7MpK5Q3pPBvO8Bnkn3/9XeyysXt+ibblbu7ieAxpuVp5oJPB08XwBcFdysPOy6QuHuS0neJ6AlM4Efe9LrQF8zG5oFdYXC3be7+4rg+UFgHWfe67jTl1mGdXW6YBkcCl4WBo/mZ3l0+nsyw7pCYWblwPXAf7bQpF2XVy4GfbqblTf/Yz/tZuVA483Kw64L4Obgo/4CM4ulGR+GTGsPw18FH71/Y2ajO3vmwUfmCSS3BlOFuszOUheEsMyC3RArgV3AS+7e4vLqxPdkJnVBOO/Jx4D/AyRaGN+uyysXg74tNyvvSJnM81fAcHcfB7zMqTV22MJYXplYQfL6HeOB7wC/6MyZm1lP4Dngy+5+oPnoNF06ZZmdo65Qlpm7N7h7Bcn7Qk82szHNmoSyvDKoq9Pfk2b2d8Aud19+tmZphp338srFoG/LzcpDrcvd97j78eDlD4FJHVxTprLyJu7ufqDxo7e7LwIKzWxgZ8zbzApJhunP3P35NE1CWWbnqivMZRbMcz+wBJjWbFQY78lz1hXSe/JyYIaZfUByF+8nzOynzdq06/LKxaBvy83KQ62r2T7cGST3sWaDhcDtwZkkU4A6d98edlFmNqRxv6SZTSb597qnE+ZrJO+DvM7d/72FZp2+zDKpK4xlZmalZtY3eN4NuBp4p1mzTn9PZlJXGO9Jd/9ndy939+Ekc+L37n5bs2bturzOeXPwbONtuFl5FtT1j2Y2g+SN0veSPOLf4czs5yTPxhhoZjXA10kemMLdvw8sInkWyQbgCPD5LKlrFvA/zaweOArM6YQVNiS3uD4LvBXs3wX4CjAspbYwllkmdYWxzIYCT5tZlOSKZb67/zrs92SGdYXynkynI5eXLoEgIpLncnHXjYiItIKCXkQkzynoRUTynIJeRCTPKehFRPKcgl5EJM8p6EVE8tz/B7M9PfOvXeyeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face frontend - file run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "from PIL import Image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "model = load_model('facefeatures_new_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the cascades\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing some Face Recognition with the webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, frame = video_capture.read()\n",
    "    #canvas = detect(gray, frame)\n",
    "    #image, face =face_detector(frame)\n",
    "    \n",
    "    face=face_extractor(frame)\n",
    "    if type(face) is np.ndarray:\n",
    "        face = cv2.resize(face, (224, 224))\n",
    "        im = Image.fromarray(face, 'RGB') #convert to RGB scale \n",
    "           #Resizing into 128x128 because we trained the model with this image size.\n",
    "        img_array = np.array(im) \n",
    "                    #Our keras model used a 4D tensor, (images x height x width x channel)\n",
    "                    #So changing dimension 128x128x3 into 1x128x128x3 \n",
    "        img_array = np.expand_dims(img_array, axis=0) \n",
    "        pred = model.predict(img_array)\n",
    "        print(pred)\n",
    "                     \n",
    "        name=\"None matching\"\n",
    "        \n",
    "        if(pred[0][3]>0.5):\n",
    "            name='Ria'\n",
    "        elif(pred[0][2]>0.5):\n",
    "            name='Karan'    \n",
    "        cv2.putText(frame,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2) \n",
    "    else:\n",
    "        cv2.putText(frame,\"No face found\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The various industry segments using and applying facial recognition technologies\n",
    "\n",
    "1. Security companies are using facial recognition to secure their premises.\n",
    "2. Immigration checkpoints use facial recognition to enforce smarter border control.\n",
    "3. Fleet management companies can use face recognition to secure their vehicles.\n",
    "4. Ride-sharing companies can use facial recognition to ensure the right passengers are picked up by the right drivers.\n",
    "5. IoT benefits from facial recognition by allowing enhanced security measures and automatic access control at home.\n",
    "6. Law Enforcement can use facial recognition technologies as one part of AI-driven surveillance systems.\n",
    "7. Retailers can use facial recognition to customize offline offerings and to theoretically map online purchasing habits with      their online ones.\n",
    "8. Google incorporates the technology into Google Photos and uses it to sort pictures and automatically tag them based on the      people recognized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Face recognition is an emerging technology that can provide many benefits. Face recognition can save resources and time, and even generate new income streams, for companies that implement it right. It has come a long way in the last twenty years. Today, machines are able to automatically verify identity information for secure transactions, for surveillance and security tasks, and for access control to buildings etc. It’s difficult to be certain. Some experts predict that our faces will replace IDs, passports and credit card pin numbers. Given the fact how convenient and cost-effective this technology is, this prediction is not far-fetched. If this prediction becomes a reality, any company that implemented the technology today might gain a competitive advantage in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
